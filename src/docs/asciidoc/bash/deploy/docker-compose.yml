version: '3'
services:
  nacos:
    image: nacos/nacos-server:2.0.2
    hostname: "nacos-standalone"
    container_name: nacos-master
    environment:
      - MODE=standalone
      - TZ=Asia/Shanghai
    volumes:
      - ${DOCKER_DIR}/nacos/master/logs:/home/nacos/logs
      - ${DOCKER_DIR}/nacos/master/init.d/custom.properties:/home/nacos/init.d/custom.properties
    ports:
      - 8848:8848
    restart: always
    networks:
      jcohy_net:
        ipv4_address: 172.30.0.48

  sentinel:
    image: bladex/sentinel-dashboard:1.6.0
    hostname: "sentinel"
    container_name: sentinel
    environment:
      - TZ=Asia/Shanghai
    ports:
      - 8858:8858
    restart: on-failure
    networks:
      jcohy_net:
        ipv4_address: 172.30.0.58
  zipkin:
    image: openzipkin/zipkin
    hostname: "zipkin"
    container_name: zipkin
    environment:
      - TZ=Asia/Shanghai
    ports:
      - 9411:9411
    restart: always
    networks:
      jcohy_net:
        ipv4_address: 172.30.0.68

  minio:
    image: minio/minio
    hostname: "minio"
    container_name: minio
    environment:
      MINIO_ACCESS_KEY: minio
      MINIO_SECRET_KEY: minio123
    volumes: 
      - ${DOCKER_DIR}/minio/data:/data
      - ${DOCKER_DIR}/minio/config:/root/.minio
    ports:
      - 9001:9000
    command: "server /data"
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://minio:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - jcohy_net
      
  api-nginx:
    image: nginx:latest
    hostname: "api-nginx"
    container_name: api-nginx
    environment:
      - TZ=Asia/Shanghai
    ports:
      - 88:88
    volumes:
      - ${DOCKER_DIR}/nginx/api/conf/nginx.conf:/etc/nginx/nginx.conf
    privileged: true
    restart: always
    networks:
      - jcohy_net

  web-nginx:
    image: nginx:latest
    hostname: "web-nginx"
    container_name: web-nginx
    environment:
      - TZ=Asia/Shanghai
    ports:
      - 8000:8000
    volumes:
      - ${DOCKER_DIR}/nginx/web/html:/usr/share/nginx/html
      - ${DOCKER_DIR}/nginx/web/conf/nginx.conf:/etc/nginx/nginx.conf
    privileged: true
    restart: always
    networks:
      - jcohy_net

  redis-master:
    image: redis:6.2-alpine
    hostname: "redis-master"
    container_name: redis-master
    environment:
      - TZ=Asia/Shanghai
    ports:
      - 6379:6379
    volumes:
      - ${DOCKER_DIR}/redis/data:/data
      - ${DOCKER_DIR}/redis/conf:/etc/redis/conf
    command: "redis-server /etc/redis/conf/redis.conf --appendonly yes"
    privileged: true
    restart: always
    networks:
      - jcohy_net

  rabbitmq-management:
    image: rabbitmq:3.8-management
    hostname: "rabbitmq-management"
    container_name: rabbitmq
    environment:
      - TZ=Asia/Shanghai
      - RABBITMQ_DEFAULT_USER=xwAdmin
      - RABBITMQ_DEFAULT_PASS=qwewsxzxc@123A
    volumes:
      - ${DOCKER_DIR}/rabbitmq/data:/var/lib/rabbitmq
    ports:
      - 5672:5672
      - 15672:15672
    privileged: true
    restart: always
    networks:
      - jcohy_net

  es-master:
    container_name: es-master
    hostname: es-master
    image: elasticsearch:7.9.3
    restart: always
    ports:
      - 9200:9200
      - 9300:9300
    volumes:
      - ${DOCKER_DIR}/elasticsearch/master/conf/es-master.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - ${DOCKER_DIR}/elasticsearch/master/data:/usr/share/elasticsearch/data
      - ${DOCKER_DIR}/elasticsearch/master/logs:/usr/share/elasticsearch/logs
    environment:
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    networks:
      - jcohy_net
      
  es-slave1:
    container_name: es-slave1
    image: elasticsearch:7.9.3
    restart: always
    ports:
      - 9201:9200
      - 9301:9300
    volumes:
      - ${DOCKER_DIR}/elasticsearch/slave1/conf/es-slave1.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - ${DOCKER_DIR}/elasticsearch/slave1/data:/usr/share/elasticsearch/data
      - ${DOCKER_DIR}/elasticsearch/slave1/logs:/usr/share/elasticsearch/logs
    environment:
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    networks:
      - jcohy_net
      
  es-slave2:
    container_name: es-slave2
    image: elasticsearch:7.9.3
    restart: always
    ports:
      - 9202:9200
      - 9302:9300
    volumes:
      - ${DOCKER_DIR}/elasticsearch/slave2/conf/es-slave2.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - ${DOCKER_DIR}/elasticsearch/slave2/data:/usr/share/elasticsearch/data
      - ${DOCKER_DIR}/elasticsearch/slave2/logs:/usr/share/elasticsearch/logs
    environment:
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    networks:
      - jcohy_net
      
  es-head:
    container_name: es-head
    image: mobz/elasticsearch-head:5
    restart: always
    ports:
      - 9100:9100
    depends_on:
      - es-master
      - es-slave1
      - es-slave2
    networks:
      - jcohy_net
      
  kibana:
    container_name: kibana
    hostname: kibana
    image: kibana:7.9.3
    restart: always
    ports:
      - 5601:5601
    volumes:
      - ${DOCKER_DIR}/kibana/conf/kibana.yml:/usr/share/kibana/config/kibana.yml
    environment:
      - elasticsearch.hosts=http://es-master:9200
    depends_on:
      - es-master
      - es-slave1
      - es-slave2
    networks:
      - jcohy_net
      
  filebeat:
    # 容器名称
    container_name: filebeat
    # 主机名称
    hostname: filebeat
    # 镜像
    image: docker.elastic.co/beats/filebeat:7.9.3
    # 重启机制
    restart: always
    # 持久化挂载
    volumes:
      - ${DOCKER_DIR}/filebeat/conf/filebeat.yml:/usr/share/filebeat/filebeat.yml
      # 映射到容器中[作为数据源]
      - ${DOCKER_DIR}/logs:/home/project/elk/logs
      - ${DOCKER_DIR}/filebeat/logs:/usr/share/filebeat/logs
      - ${DOCKER_DIR}/filebeat/data:/usr/share/filebeat/data
    # 将指定容器连接到当前连接，可以设置别名，避免ip方式导致的容器重启动态改变的无法连接情况
    links:
      - logstash
    ports:
      - 9000:9000
    # 依赖服务[可无]
    depends_on:
      - es-master
      - es-slave1
      - es-slave2
    networks:
      - jcohy_net
      
  logstash:
    container_name: logstash
    hostname: logstash
    image: logstash:7.9.3
    command: logstash -f ./conf/logstash-filebeat.conf
    restart: always
    volumes:
      # 映射到容器中
      - ${DOCKER_DIR}/logstash/conf/logstash-filebeat.conf:/usr/share/logstash/conf/logstash-filebeat.conf
      - ${DOCKER_DIR}/logstash/conf/logstash.yml:/usr/share/logstash/config/logstash.yml
    ports:
      - 5044:5044
    depends_on:
      - es-master
      - es-slave1
      - es-slave2
    networks:
      - jcohy_net
      
networks:
  jcohy_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/16
